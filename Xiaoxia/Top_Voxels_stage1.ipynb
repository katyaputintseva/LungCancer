{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Danniel's github\n",
    "\n",
    "\n",
    "https://github.com/dhammack/DSB2017/blob/50ea5d169f6028b907b40276502e744c6b9d12ec/training_code/FLung_nodule_models/score_ident_model_v1.py\n",
    "\n",
    "\n",
    "https://github.com/dhammack/DSB2017/blob/master/scoring_code/score_ident_model_v1_stage2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from joblib import Parallel, delayed\n",
    "import sys\n",
    "import scipy\n",
    "import cv2\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_start(arr, thresh=.5):\n",
    "\t#determine when the arr first exceeds thresh\n",
    "\t#arr = arr.ravel()\n",
    "\tfor i in range(arr.shape[0]):\n",
    "\t\tif arr[i] > thresh:\n",
    "\t\t\t#print 'returning', i\n",
    "\t\t\treturn np.clip(i - 8, 0, arr.shape[0])\n",
    "\treturn 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_strides(steps,size,offset,VOXEL_SIZE):\n",
    "\tif steps * VOXEL_SIZE < size - 2*offset:\n",
    "\t\t#not enough coverage. start and end are modified\n",
    "\t\tstart = (size - steps*VOXEL_SIZE) / 2\n",
    "\t\tend = size - start - VOXEL_SIZE\n",
    "\telse:\n",
    "\t\tstart = offset\n",
    "\t\tend = size-VOXEL_SIZE - offset\n",
    "\treturn list(np.around(np.linspace(start,end,steps)).astype('int32'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Danniel's code, the preds are in the original scale (from 0 to 5), and he uses thresh=1.5. That means he is only keeping voxels with malignancy score higher then 1.5. \n",
    "\n",
    "Our CNN is giving normalized malignancy preds (from 0 to 1), if we use thresh = 1.5/5=0.3, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_interesting_ixs(preds,thresh=0.35,max_ct=50):\n",
    "\t#return the indices of interest\n",
    "\tixs = []\n",
    "\t# preds_at_ixs = []\n",
    "\tfor i in range(preds.shape[0]):\n",
    "\t\tif preds[i] > thresh:\n",
    "\t\t\tixs.append(i)\n",
    "\t\t\t# preds_at_ixs.append(preds[i])\n",
    "\t\t\t\n",
    "\tif len(ixs) == 0:\n",
    "\t\tixs = [np.argmax(preds)]\n",
    "\t\t# preds_at_ixs = [preds[np.argmax(preds)]]\n",
    "\t\t\n",
    "\tif len(ixs) > max_ct:\n",
    "\t\tixs = np.argsort(preds)[-max_ct:]\n",
    "\t\t\n",
    "\treturn np.array(ixs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_to_vox(img,VOXEL_SIZE,mask):\n",
    "\n",
    "\t#mask == 0 -> inside lung.\n",
    "\t#mask == 1 -> outside lung \n",
    "\t\n",
    "\t#first let's just get the minimum amount of coverage\n",
    "\tsamples0 = int(img.shape[0] / float(VOXEL_SIZE)) + 4\n",
    "\tsamples1 = int(img.shape[1] / float(VOXEL_SIZE)) + 4\n",
    "\tsamples2 = int(img.shape[2] / float(VOXEL_SIZE)) + 4\n",
    "\t\n",
    "\tixs0 = get_strides(samples0,img.shape[0],0,VOXEL_SIZE)\n",
    "\tixs1 = get_strides(samples1,img.shape[1],0,VOXEL_SIZE)\n",
    "\tixs2 = get_strides(samples2,img.shape[2],0,VOXEL_SIZE)\n",
    "\n",
    "\tsubvoxels = []\n",
    "\tlocations = []\n",
    "\tcentroids = []\n",
    "\tfor i0,x0 in enumerate(ixs0):\n",
    "\t\tfor i1,x1 in enumerate(ixs1):\n",
    "\t\t\tfor i2,x2 in enumerate(ixs2):\n",
    "\t\t\t\tif mask[x0:x0+VOXEL_SIZE,x1:x1+VOXEL_SIZE,x2:x2+VOXEL_SIZE].mean() > .99:\n",
    "\t\t\t\t\t#basically no lung in this voxel, might as well ignore.\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tsubvoxels.append(img[x0:x0+VOXEL_SIZE,x1:x1+VOXEL_SIZE,x2:x2+VOXEL_SIZE])\n",
    "\t\t\t\tassert subvoxels[-1].shape == (VOXEL_SIZE,VOXEL_SIZE,VOXEL_SIZE), 'bad subvoxel shape ' + str(subvoxels[-1].shape) + ' ' + str([x0,x1,x2]) + ' ' + str(img.shape)\n",
    "\t\t\t\tlocations.append((i0,i1,i2))\n",
    "\t\t\t\tcentroids.append((x0+VOXEL_SIZE/2,x1+VOXEL_SIZE/2,x2+VOXEL_SIZE/2))\n",
    "\tX = np.stack(subvoxels, axis=0)\n",
    "\t#print 'num subvoxels:', X.shape[0]\n",
    "\tX = np.expand_dims(X, 1)\n",
    "\t#normalized locations\n",
    "\t#allows us to de-weight certain places...\n",
    "\t\n",
    "\treturn X,locations,centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop_img(img_cpy):\n",
    "\t# img_raw = np.load(patient)\n",
    "\t# downsample = 1\n",
    "\tmasks = []\n",
    "\timg_raw = img_cpy.copy()\n",
    "\t\n",
    "\tfor i in range(img_raw.shape[2]):\n",
    "\t\timg_slice = img_raw[ :,:,i]\n",
    "\t\timg = img_slice.copy()\n",
    "\n",
    "\t\timg[img>-300] = 255\n",
    "\t\timg[img<-300] = 0\n",
    "\t\timg = np.uint8(img)\n",
    "\t\t_, contours, _ = cv2.findContours(img,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\t\tif len(contours) > 0:\n",
    "\t\t\n",
    "\n",
    "\t\t\tlargest_contour = max(contours, key=cv2.contourArea)\n",
    "\t\telse:\n",
    "\t\t\tmask = (np.zeros(img.shape, np.uint8) < 255)\n",
    "\t\t\tmasks.append(mask)\n",
    "\t\t\tcontinue\n",
    "\t\tmask = np.zeros(img.shape, np.uint8)\n",
    "\t\tcv2.fillPoly(mask, [largest_contour], 255)\n",
    "\n",
    "#\t\t imshow(mask); show()\n",
    "\n",
    "\t\t# apply mask to threshold image to remove outside. this is our new mask\n",
    "\t\timg = ~img \n",
    "\t\timg[(mask == 0)] = 0 # <-- Larger than threshold value\n",
    "\n",
    "\t\t# apply closing to the mask\n",
    "\t\tkernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n",
    "\t\timg = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)  # <- to remove speckles...\n",
    "\t\timg = cv2.morphologyEx(img, cv2.MORPH_DILATE, kernel)\n",
    "\t\timg = cv2.morphologyEx(img, cv2.MORPH_DILATE, kernel)\n",
    "\t\timg = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "\t\timg = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "\t\timg = cv2.morphologyEx(img, cv2.MORPH_ERODE, kernel)\n",
    "\t\timg = cv2.morphologyEx(img, cv2.MORPH_ERODE, kernel)\n",
    "\n",
    "\t\t#the image has an outside part which we don't care about (value 0)\n",
    "\t\t#and a boundary that we don't care about (value 255)\n",
    "\t\t#and some noise that we don't care about (value 125)\n",
    "\t\tmask = (img < 255)\n",
    "#\t\t img_raw[~mask] = -2000\n",
    "#\t\t imshow(img_raw); colorbar(); show()\n",
    "\t\tmasks.append(mask)\n",
    "\t\n",
    "\t#now we have one mask per slice. To determine our bounding box, take the max x,y,z plus a fuzz factor\n",
    "\tixs_to_remove = [i for i,m in enumerate(masks) if np.mean(m) > .995]\n",
    "\t\n",
    "\t# masks =[m for m in masks if np.mean(m) < .995]\n",
    "\tmasks = np.stack(masks, axis=2)\n",
    "\tmasks = np.delete(masks, ixs_to_remove, axis=2)\n",
    "\timg_raw = np.delete(img_raw, ixs_to_remove, axis=2)\n",
    "\t\n",
    "\t\n",
    "\t#0 = mask, 1 = background\n",
    "\tx_dim = np.min(masks, axis=(1,2))\n",
    "\ty_dim = np.min(masks, axis=(0,2))\n",
    "\tz_dim = np.min(masks, axis=(0,1))\n",
    "\t\n",
    "\txstart = find_start(1 - x_dim, .5)\n",
    "\txend = -(find_start(1 - x_dim[::-1], .5) + 1)\n",
    "\t\n",
    "\tystart = find_start(1 - y_dim, .5)\n",
    "\tyend = -(find_start(1 - y_dim[::-1], .5) + 1)\n",
    "\t\n",
    "\t\n",
    "\tzstart = find_start(1 - z_dim, .5)\n",
    "\tzend = -( find_start(1 - z_dim[::-1], .5) + 1)\n",
    "\t\n",
    "\t# try:\n",
    "\tassert xstart < int(img_raw.shape[0]*.5) < img_raw.shape[0] - xend, 'bad crop ' + str(xstart) + ' ' + str(xend) + ' ' + str(img_raw.shape[0])\n",
    "\tassert ystart < int(img_raw.shape[1]*.5) < img_raw.shape[1] - yend, 'bad crop ' + str(ystart) + ' ' + str(yend) + ' ' + str(img_raw.shape[1])\n",
    "\tassert zstart < int(img_raw.shape[2]*.5) < img_raw.shape[2] - zend, 'bad crop ' + str(zstart) + ' ' + str(zend) + ' ' + str(img_raw.shape[2])\n",
    "\tassert xend < 0 and yend < 0 and zend < 0, 'one end >= 0'\n",
    "\tassert xstart >= 0 and ystart >= 0 and zstart >= 0, 'one start <= 0'\n",
    "\t# except AssertionError as e:\n",
    "\t\t# print 'WARNING cropping failed. using full img', e\n",
    "\t\t# return img_raw\n",
    "\t\t\n",
    "\treturn img_raw[xstart:xend,ystart:yend,zstart:zend], masks[xstart:xend,ystart:yend,zstart:zend]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_and_txform_file(file,model,VOXEL_SIZE,batch_size,n_TTA=32):\n",
    "\t#read, convert to voxels.\n",
    "\txorig = np.load(os.path.join(\"../../data/stage1_arrays/\", file))\n",
    "\tx = np.clip(xorig.copy(), -1000, 400)\n",
    "\tx,mask = crop_img(x)\n",
    "\n",
    "\tx = ((x + 1000.) / (400. + 1000.)).astype('float32')\n",
    "\tvoxels, locs, centroids = img_to_vox(x,VOXEL_SIZE,mask)\n",
    "\t#predict on voxels, keep top N ROI\n",
    "\tpreds = model.predict(voxels, batch_size=batch_size).ravel()\n",
    "\t\n",
    "\ttopNixs = get_interesting_ixs(preds)\n",
    "\ttopNvox = voxels[topNixs]\n",
    "\ttopNcentroids = np.array(centroids)[topNixs]\n",
    "\ttopNpreds = preds[topNixs]\n",
    "\t\n",
    "\treturn topNvox, topNcentroids, [x.shape] * topNcentroids.shape[0], topNpreds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient numbers:  1434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.5/site-packages/keras/engine/topology.py:1206: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  return cls(**config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337e7a428e7342d1e7f53a04247f7ad8.npy\n"
     ]
    }
   ],
   "source": [
    "PATH_RAW_ARRAY = \"../../data/stage1_arrays/\"\n",
    "PATH_VOXELS = \"../../data/stage1_TOP_voxels/\"\n",
    "PATH_MODEL = \"../Models/LUNA_model_v2.h5\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    patients = [f for f in os.listdir(PATH_RAW_ARRAY) if '.npy' in f ]\n",
    "    print (\"patient numbers: \", len(patients) )    \n",
    "    model_v24 = load_model(PATH_MODEL)\n",
    "    VOXEL_SIZE = 64\n",
    "    \n",
    "    for num, patient in enumerate(patients):\n",
    "        if num%100 == 0:\n",
    "            print (\"%d patients saved\"%num)\n",
    "        vox, cents, shapes, preds = load_and_txform_file(patient, model_v24, VOXEL_SIZE, batch_size=32, n_TTA=2)\n",
    "        print (\"hi\")\n",
    "        np.save(join(PATH_VOXELS, 'vox_' + patient), vox)\n",
    "        np.save(join(PATH_VOXELS, 'cents_' + patient), cents)\n",
    "        np.save(join(PATH_VOXELS, 'shapes_' + patient), shapes)\n",
    "        np.save(join(PATH_VOXELS, 'preds_' + patient), preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(1,5):\n",
    "    xorig = np.load(os.path.join(\"../../data/stage1_arrays/\", patients[i]))\n",
    "    print (\"\\npatient: \", patients[i])\n",
    "    print (\"original shape:\", xorig.shape)\n",
    "    x = np.clip(xorig.copy(), -1000, 400)\n",
    "\n",
    "    x,mask = crop_img(x)\n",
    "    x = ((x + 1000.) / (400. + 1000.)).astype('float32')\n",
    "    print (\"croped img shape:\",x.shape)\n",
    "    voxels, locs, centroids = img_to_vox(x,VOXEL_SIZE,mask)\n",
    "    preds = model_v24.predict(voxels, batch_size=20).ravel()\n",
    "    print (\"malignancy range: \", np.min(preds), np.max(preds)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (np.min(preds), np.max(preds)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
