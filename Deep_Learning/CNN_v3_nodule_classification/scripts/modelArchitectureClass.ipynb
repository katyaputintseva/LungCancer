{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.pooling import AveragePooling3D, GlobalMaxPooling3D\n",
    "from keras.layers import Input, merge, Activation, Dropout\n",
    "from keras.optimizers import Adamax, Adam, Nadam, sgd\n",
    "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,LearningRateScheduler,EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def learningRateSchedule(epoch):\n",
    "    if epoch  < 2:\n",
    "        return 1e-2\n",
    "    if epoch < 5:\n",
    "        return 1e-3\n",
    "    if epoch < 10:\n",
    "        return 5e-4\n",
    "    return 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compileModel(inputShape, dropRate, regRate):\n",
    "    \n",
    "    x = Input(inputShape)\n",
    "    \n",
    "    x1 = convCNNBlock(x, 8, dropRate=0, regRate=regRate)\n",
    "    x1Pool = AveragePooling3D(dim_ordering=\"th\")(x)\n",
    "    x1Merged = merge([x1, x1Pool], mode='concat', concat_axis=1)\n",
    "    \n",
    "    x2 = convCNNBlock(x1Merged, 24, dropRate=0, regRate=regRate)\n",
    "    x2Pool = AveragePooling3D(dim_ordering=\"th\")(x1Pool)\n",
    "    x2Merged = merge([x2, x2Pool], mode='concat', concat_axis=1)\n",
    "    \n",
    "    x3 = convCNNBlock(x2Merged, 48, dropRate=0, regRate=regRate)\n",
    "    x3Pool = AveragePooling3D(dim_ordering=\"th\")(x2Pool)\n",
    "    x3Merged = merge([x3,x3Pool], mode='concat', concat_axis=1)\n",
    "\n",
    "    x4 = convCNNBlock(x3Merged, 64, dropRate=0, regRate=regRate)\n",
    "    x4Pool = AveragePooling3D(dim_ordering=\"th\")(x3Pool)\n",
    "    x4Merged = merge([x4, x4Pool], mode='concat', concat_axis=1)\n",
    "\n",
    "    x5 = convCNNBlock(x4Merged, 65, dropRate=0, regRate=regRate)\n",
    "    \n",
    "    xMaxPool = GlobalMaxPooling3D()(x5)\n",
    "    xMaxPoolNorm = BatchNormalization()(xMaxPool) \n",
    "    \n",
    "    xOut = denseCNNBlock(xMaxPoolNorm, name='Nodule', outSize=2, activation='softmax', \n",
    "                         dropRate=dropRate, regRate=regRate, neuronNumber=5)\n",
    "    \n",
    "    model = Model(input=x, output=xOut)\n",
    "\n",
    "#     opt = sgd(0.01, nesterov=True)\n",
    "    opt = Nadam()\n",
    "    \n",
    "    print ('Compiling model...')\n",
    "    \n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='categorical_crossentropy',\n",
    "                metrics=['categorical_accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomFlips(Xbatch):\n",
    "    \n",
    "    swaps = np.random.choice([-1,1],size=(Xbatch.shape[0],3))\n",
    "    for i in range(Xbatch.shape[0]):\n",
    " \n",
    "        Xbatch[i] = Xbatch[i,::swaps[i,0],::swaps[i,1],::swaps[i,2]]\n",
    "        \n",
    "    return Xbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainModelClass(model, modelPath, testSize=0.2, batchSize=10, nbEpoch = 1, stepsPerEpoch = 2, fp=False):\n",
    "    \n",
    "    print ('Loading positive patches')\n",
    "    xPos = loadCategoryClass('true')\n",
    "#     xPos = randomFlips(xPos)\n",
    "    xPosTrain,xPosValid,indPosTrain,indPosValid = train_test_split(xPos, \n",
    "                                                np.array([n for n in range(xPos.shape[0])]), \n",
    "                                                test_size=testSize)\n",
    "    ixPosTrainClass = np.ones((xPosTrain.shape[0]))\n",
    "    ixPosValidClass = np.ones((xPosValid.shape[0]))\n",
    "    del xPos\n",
    "    \n",
    "    print ('Loading negative patches')\n",
    "    xNeg = loadCategoryClass('random')\n",
    "    \n",
    "    xNegTrain,xNegValid,indNegTrain,indNegValid = train_test_split(xNeg, \n",
    "                                                np.array([n for n in range(xNeg.shape[0])]), \n",
    "                                                test_size=testSize)\n",
    "    ixNegTrainClass = np.zeros((xNegTrain.shape[0]))\n",
    "    ixNegValidClass = np.zeros((xNegValid.shape[0]))\n",
    "    del xNeg\n",
    "    \n",
    "    trainGenerator = batchGeneratorClass(xPosTrain,xNegTrain,\n",
    "                                    ixPosTrainClass,ixNegTrainClass,\n",
    "                                    batchSize=batchSize,\n",
    "                                    posFraction=.5)\n",
    "\n",
    "    validGenerator = batchGeneratorClass(xPosValid,xNegValid,\n",
    "                                    ixPosValidClass,ixNegValidClass,\n",
    "                                    batchSize=batchSize,\n",
    "                                    posFraction=.5)\n",
    "        \n",
    "    ckp = ModelCheckpoint(filepath=modelPath)\n",
    "        \n",
    "    lr = LearningRateScheduler(learningRateSchedule)\n",
    "    es = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=0, mode='auto')\n",
    "    \n",
    "    lossHist = {'loss':[], 'val_loss':[], 'val_categorical_accuracy':[], 'categorical_accuracy':[]}\n",
    "    \n",
    "    for epoch in range(nbEpoch):\n",
    "        hist = model.fit_generator(trainGenerator, validation_data=validGenerator, \n",
    "                                   validation_steps=10,steps_per_epoch=stepsPerEpoch,\n",
    "                                   nb_epoch=epoch+1,callbacks=[ckp],\n",
    "                                   initial_epoch=epoch)\n",
    "        for key in hist.history:\n",
    "            lossHist[key].extend(hist.history[key])\n",
    "\n",
    "    return model, lossHist, indPosValid, indNegValid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
