{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.pooling import AveragePooling3D, GlobalMaxPooling3D\n",
    "from keras.layers import Input, merge, Activation, Dropout\n",
    "from keras.optimizers import Adamax, Adam, Nadam, sgd\n",
    "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,LearningRateScheduler,EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def learningRateSchedule(epoch):\n",
    "    if epoch  < 2:\n",
    "        return 1e-2\n",
    "    if epoch < 5:\n",
    "        return 1e-3\n",
    "    if epoch < 10:\n",
    "        return 5e-4\n",
    "    return 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compileModel(inputShape, dropRate):\n",
    "    \n",
    "    x = Input(inputShape)\n",
    "    \n",
    "    x1 = convCNNBlock(x, 8, dropRate=dropRate)\n",
    "    x1Pool = AveragePooling3D(dim_ordering=\"th\")(x)\n",
    "    x1Merged = merge([x1, x1Pool], mode='concat', concat_axis=1)\n",
    "    \n",
    "    x2 = convCNNBlock(x1Merged, 24, dropRate=dropRate)\n",
    "    x2Pool = AveragePooling3D(dim_ordering=\"th\")(x1Pool)\n",
    "    x2Merged = merge([x2, x2Pool], mode='concat', concat_axis=1)\n",
    "    \n",
    "    x3 = convCNNBlock(x2Merged, 48, dropRate=dropRate)\n",
    "    x3Pool = AveragePooling3D(dim_ordering=\"th\")(x2Pool)\n",
    "    x3Merged = merge([x3,x3Pool], mode='concat', concat_axis=1)\n",
    "\n",
    "    x4 = convCNNBlock(x3Merged, 64, dropRate=dropRate)\n",
    "    x4Pool = AveragePooling3D(dim_ordering=\"th\")(x3Pool)\n",
    "    x4Merged = merge([x4, x4Pool], mode='concat', concat_axis=1)\n",
    "\n",
    "    x5 = convCNNBlock(x4Merged, 65, dropRate=dropRate)\n",
    "    \n",
    "    xMaxPool = GlobalMaxPooling3D()(x5)\n",
    "    xMaxPoolNorm = BatchNormalization()(xMaxPool) \n",
    "    \n",
    "    xMalig = denseCNNBlock(xMaxPoolNorm, name='Malignancy', outSize=1, activation='softplus', dropRate=dropRate)\n",
    "    xDiam = denseCNNBlock(xMaxPoolNorm, name='Diameter', outSize=1, activation='softplus', dropRate=dropRate)\n",
    "    xLob = denseCNNBlock(xMaxPoolNorm, name='Lobulation', outSize=1, activation='softplus', dropRate=dropRate)\n",
    "    xSpic = denseCNNBlock(xMaxPoolNorm, name='Spiculation', outSize=1, activation='softplus', dropRate=dropRate)\n",
    "    \n",
    "    model = Model(input=x, output=[xMalig, xDiam, xLob, xSpic])\n",
    "\n",
    "#     opt = Nadam(0.01, clipvalue=1.0)\n",
    "    opt = sgd(0.01, nesterov=True, )\n",
    "    \n",
    "    print ('Compiling model...')\n",
    "    \n",
    "    model.compile(optimizer=opt,\n",
    "                  loss={'Malignancy':'mse', 'Diameter':'mse', 'Lobulation':'mse',\n",
    "                       'Spiculation':'mse'},\n",
    "                  loss_weights={'Malignancy':1, 'Diameter':1, 'Lobulation':1,\n",
    "                       'Spiculation':1})\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compileModelDeepBranching(inputShape, dropRate):\n",
    "    \n",
    "    dropRate=1e-2\n",
    "    \n",
    "    x = Input(inputShape)\n",
    "    \n",
    "    x1 = convCNNBlock(x, 8, dropRate=dropRate)\n",
    "    x1Pool = AveragePooling3D(dim_ordering=\"th\")(x)\n",
    "    x1Merged = merge([x1, x1Pool], mode='concat', concat_axis=1)\n",
    "    \n",
    "    x2 = convCNNBlock(x1Merged, 24, dropRate=dropRate)\n",
    "    x2Pool = AveragePooling3D(dim_ordering=\"th\")(x1Pool)\n",
    "    x2Merged = merge([x2, x2Pool], mode='concat', concat_axis=1)\n",
    "    \n",
    "    x3 = convCNNBlock(x2Merged, 48, dropRate=dropRate)\n",
    "    x3Pool = AveragePooling3D(dim_ordering=\"th\")(x2Pool)\n",
    "    x3Merged = merge([x3,x3Pool], mode='concat', concat_axis=1)\n",
    "\n",
    "    x4 = convCNNBlock(x3Merged, 64, dropRate=dropRate)\n",
    "    x4Pool = AveragePooling3D(dim_ordering=\"th\")(x3Pool)\n",
    "    x4Merged = merge([x4, x4Pool], mode='concat', concat_axis=1)\n",
    "    \n",
    "    \n",
    "    ###Malignancy###\n",
    "    x5Malig = convCNNBlock(x4Merged, 65, dropRate=dropRate)\n",
    "    xMaxPoolMalig = GlobalMaxPooling3D()(x5Malig)\n",
    "    xMaxPoolNormMalig = BatchNormalization()(xMaxPoolMalig) \n",
    "    xMalig = denseCNNBlock(xMaxPoolNormMalig, name='Malignancy', \n",
    "                           outSize=1, activation='softplus', \n",
    "                           dropRate=dropRate)\n",
    "    \n",
    "    ###Diameter###\n",
    "    x5Diam = convCNNBlock(x4Merged, 65, dropRate=dropRate)\n",
    "    xMaxPoolDiam = GlobalMaxPooling3D()(x5Diam)\n",
    "    xMaxPoolNormDiam = BatchNormalization()(xMaxPoolDiam) \n",
    "    xDiam = denseCNNBlock(xMaxPoolNormDiam, name='Diameter', \n",
    "                          outSize=1, activation='softplus', \n",
    "                          dropRate=dropRate)\n",
    "    \n",
    "    ###Lobulation###\n",
    "    x5Lob = convCNNBlock(x4Merged, 65, dropRate=dropRate)\n",
    "    xMaxPoolLob = GlobalMaxPooling3D()(x5Lob)\n",
    "    xMaxPoolNormLob = BatchNormalization()(xMaxPoolLob) \n",
    "    xLob = denseCNNBlock(xMaxPoolNormLob, name='Lobulation', \n",
    "                         outSize=1, activation='softplus', \n",
    "                         dropRate=dropRate)\n",
    "    \n",
    "    ###Spiculation###\n",
    "    x5Spic = convCNNBlock(x4Merged, 65, dropRate=dropRate)\n",
    "    xMaxPoolSpic = GlobalMaxPooling3D()(x5Spic)\n",
    "    xMaxPoolNormSpic = BatchNormalization()(xMaxPoolSpic) \n",
    "    xSpic = denseCNNBlock(xMaxPoolNormSpic, name='Spiculation', \n",
    "                          outSize=1, activation='softplus', \n",
    "                          dropRate=dropRate)\n",
    "\n",
    "    \n",
    "    model = Model(input=x, output=[xMalig, xDiam, xLob, xSpic])\n",
    "\n",
    "#     opt = Nadam(0.01, clipvalue=1.0)\n",
    "    opt = sgd(0.01, nesterov=True, )\n",
    "    \n",
    "    print ('Compiling model...')\n",
    "    \n",
    "    model.compile(optimizer=opt,\n",
    "                  loss={'Malignancy':'mse', 'Diameter':'mse', 'Lobulation':'mse',\n",
    "                       'Spiculation':'mse'},\n",
    "                  loss_weights={'Malignancy':1, 'Diameter':1, 'Lobulation':1,\n",
    "                       'Spiculation':1})\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomFlips(Xbatch):\n",
    "    \n",
    "    swaps = np.random.choice([-1,1],size=(Xbatch.shape[0],3))\n",
    "    for i in range(Xbatch.shape[0]):\n",
    " \n",
    "        Xbatch[i] = Xbatch[i,::swaps[i,0],::swaps[i,1],::swaps[i,2]]\n",
    "        \n",
    "    return Xbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainModel(model, modelPath, testSize=0.2, batchSize=10, nbEpoch = 1, stepsPerEpoch = 2, fp=False):\n",
    "    \n",
    "    print ('Loading positive patches')\n",
    "    xPos, ixPos = loadCategory('true')\n",
    "    xPos = randomFlips(xPos)\n",
    "    xPosTrain,xPosValid,ixPosTrain,ixPosValid = train_test_split(xPos, ixPos, test_size=testSize)   \n",
    "    del xPos, ixPos\n",
    "    \n",
    "    print ('Loading negative patches')\n",
    "    xNeg, ixNeg = loadCategory('random')\n",
    "    xNegTrain,xNegValid,ixNegTrain,ixNegValid = train_test_split(xNeg, ixNeg, test_size=testSize)\n",
    "    del xNeg, ixNeg\n",
    "    \n",
    "    if fp==True:\n",
    "        print ('Loading false positive patches')\n",
    "        xFP, ixFP = loadCategory('false')\n",
    "        xFPTrain,xFPValid,ixFPTrain,ixFPValid = train_test_split(xFP, ixFP, test_size=testSize)\n",
    "        del xFP, ixFP\n",
    "\n",
    "        trainGenerator = batchGenerator(xPosTrain,xNegTrain,\n",
    "                                        ixPosTrain,ixNegTrain,\n",
    "                                        xFP=xFPTrain,ixFP=ixFPTrain,\n",
    "                                        batchSize=batchSize,\n",
    "                                        posFraction=.5)\n",
    "\n",
    "        validGenerator = batchGenerator(xPosValid,xNegValid,\n",
    "                                        ixPosValid,ixNegValid,\n",
    "                                        xFP=xFPValid,ixFP=ixFPValid,\n",
    "                                        batchSize=batchSize,\n",
    "                                        posFraction=.5)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        trainGenerator = batchGenerator(xPosTrain,xNegTrain,\n",
    "                                        ixPosTrain,ixNegTrain,\n",
    "                                        batchSize=batchSize,\n",
    "                                        posFraction=.5)\n",
    "\n",
    "        validGenerator = batchGenerator(xPosValid,xNegValid,\n",
    "                                        ixPosValid,ixNegValid,\n",
    "                                        batchSize=batchSize,\n",
    "                                        posFraction=.5)\n",
    "        \n",
    "        \n",
    "    ckp = ModelCheckpoint(filepath=modelPath)\n",
    "        \n",
    "    lossHist = {}\n",
    "    \n",
    "    for lossType in ['Diameter_loss', 'val_loss', \n",
    "                     'val_Lobulation_loss', 'Spiculation_loss', \n",
    "                     'loss', 'val_Diameter_loss', 'val_Spiculation_loss', \n",
    "                     'Lobulation_loss', 'val_Malignancy_loss', 'Malignancy_loss']:\n",
    "        \n",
    "        lossHist[lossType] = []\n",
    "        \n",
    "    lr = LearningRateScheduler(learningRateSchedule)\n",
    "    es = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=4, verbose=0, mode='auto')\n",
    "    \n",
    "    for epoch in range(nbEpoch):\n",
    "        hist = model.fit_generator(trainGenerator, validation_data=validGenerator, \n",
    "                                   validation_steps=20,steps_per_epoch=stepsPerEpoch,\n",
    "                                   nb_epoch=epoch+1,callbacks=[ckp, lr, es],\n",
    "                                   initial_epoch=epoch)\n",
    "        \n",
    "        for lossType in hist.history.keys():\n",
    "            lossHist[lossType].extend(hist.history[lossType])\n",
    "\n",
    "    return model, lossHist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
