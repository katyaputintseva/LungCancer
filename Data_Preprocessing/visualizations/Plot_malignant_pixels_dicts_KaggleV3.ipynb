{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def top_patients(NUM_patients=1,MODEL='feature_matrix_model3_stage1.csv'):\n",
    "    df = pd.read_csv(MODEL).sort_values(['max_malig'],ascending=[False])\n",
    "    top_patients_dict = {}\n",
    "    for i in range(NUM_patients):\n",
    "        \n",
    "        patient = df.iloc[i]['id']\n",
    "        top_patients_dict[patient] = {}\n",
    "        \n",
    "        malignancy = df.iloc[i]['max_malig']\n",
    "        top_patients_dict[patient]['max_malig'] = malignancy\n",
    "        \n",
    "        print ('Patient',i+1,':\\t',patient,'\\nMalignancy',i+1,':\\t',malignancy)\n",
    "        \n",
    "        with open('./LUNA_model_v3/dict_top_patients.pickle', 'wb') as handle:\n",
    "            pickle.dump(top_patients_dict,handle,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print ('\\tDictionary SAVED for..',patient)\n",
    "        \n",
    "    return top_patients_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 1 :\t 243038f7bb7787497c59bc17f04c6ed9 \n",
      "Malignancy 1 :\t 0.466551721096\n",
      "\tDictionary SAVED for.. 243038f7bb7787497c59bc17f04c6ed9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "top_patients_dict = top_patients()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.models import load_model\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.15\n",
    "set_session(tf.Session(config=config))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def top_patients_predict(top_patients_DICT,MODEL,TOP=1):\n",
    "    top_patients_dict = deepcopy(top_patients_DICT)\n",
    "    for patient in top_patients_dict.keys():\n",
    "        print ('Patient..',str(patient))\n",
    "        patient_load = np.load('../data/stage1_voxels_mask/'+patient+'.npz')\n",
    "        voxels = patient_load['vox']\n",
    "        print ('\\tNumber of voxels to predict..',voxels.shape[0])\n",
    "        \n",
    "        preds = np.array(MODEL.predict(x=voxels,batch_size=5))\n",
    "        top_patients_dict[patient]['preds'] = preds\n",
    "        np.save('./LUNA_model_v3/preds_'+patient+'.npy',preds)\n",
    "        print ('\\tVoxels predicted..',len(preds))\n",
    "        \n",
    "        top_ixs = np.argsort(preds[0],axis=0)[-TOP:]\n",
    "        top_ixs = [i[0] for i in top_ixs]\n",
    "        top_patients_dict[patient]['top_ixs'] = top_ixs\n",
    "        print ('\\tNumber of top voxels for visualization..',len(top_ixs))\n",
    "        \n",
    "        top_patients_dict[patient]['top_voxels'] = np.vstack([voxels[i] for i in top_ixs])\n",
    "        with open('./LUNA_model_v3/dict_top_patients_predict.pickle', 'wb') as handle:\n",
    "            pickle.dump(top_patients_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print ('\\tDictionary SAVED for..',patient)\n",
    "        \n",
    "    return top_patients_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.5/site-packages/keras/engine/topology.py:1206: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  return cls(**config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient.. 243038f7bb7787497c59bc17f04c6ed9\n",
      "\tNumber of voxels to predict.. 290\n",
      "\tVoxels predicted.. 4\n",
      "\tNumber of top voxels for visualization.. 1\n",
      "\tDictionary SAVED for.. 243038f7bb7787497c59bc17f04c6ed9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "LUNA_model_v3 = load_model('../LungCancer/Models/LUNA_model_v3_regression.h5')\n",
    "top_patients_dict = top_patients_predict(top_patients_dict,LUNA_model_v3,TOP=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def top_voxels_predict(top_patients_DICT,MODEL):\n",
    "    top_patients_dict = deepcopy(top_patients_DICT)\n",
    "    for patient in top_patients_dict.keys():\n",
    "        print ('Patient..',patient)\n",
    "        \n",
    "        top_voxels = top_patients_dict[patient]['top_voxels']\n",
    "        \n",
    "        for i in range(top_voxels.shape[0]):\n",
    "            print ('\\tPredicting voxel',i+1)\n",
    "            start = time.time()\n",
    "            \n",
    "            voxel = np.squeeze(top_voxels[i])\n",
    "            count = 0\n",
    "            preds_top_voxels = []\n",
    "            \n",
    "            for e in np.nditer(voxel,op_flags=['readwrite']):\n",
    "                e_original = e.copy()\n",
    "                e[...] = 0\n",
    "                preds = MODEL.predict(x=np.expand_dims(np.expand_dims(voxel,axis=0),axis=0),batch_size=1)\n",
    "                preds = [p[0][0] for p in preds]\n",
    "                preds_top_voxels.append(preds)\n",
    "                e[...] = e_original\n",
    "                count +=1\n",
    "                if count%1000==0:\n",
    "                    print ('\\t\\tOut of',64*64*64,',',count,'are done in',time.time()-start)\n",
    "                    start = time.time()\n",
    "            top_patients_dict[patient][i+1] = preds_top_voxels\n",
    "        \n",
    "        with open('./LUNA_model_v3/dict_top_voxels_predict.pickle', 'wb') as handle:\n",
    "            pickle.dump(top_patients_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print ('\\tDictionary SAVED for..',patient)\n",
    "        \n",
    "    return top_patients_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient.. 243038f7bb7787497c59bc17f04c6ed9\n",
      "\tPredicting voxel 1\n",
      "\t\tOut of 262144 , 1000 are done in 9.753782987594604\n",
      "\t\tOut of 262144 , 2000 are done in 9.717344522476196\n",
      "\t\tOut of 262144 , 3000 are done in 9.780884265899658\n",
      "\t\tOut of 262144 , 4000 are done in 9.744641780853271\n",
      "\t\tOut of 262144 , 5000 are done in 9.857274055480957\n",
      "\t\tOut of 262144 , 6000 are done in 9.80086350440979\n",
      "\t\tOut of 262144 , 7000 are done in 9.803893804550171\n",
      "\t\tOut of 262144 , 8000 are done in 9.854894638061523\n",
      "\t\tOut of 262144 , 9000 are done in 9.872679471969604\n",
      "\t\tOut of 262144 , 10000 are done in 9.870088338851929\n",
      "\t\tOut of 262144 , 11000 are done in 9.823622941970825\n",
      "\t\tOut of 262144 , 12000 are done in 9.872875452041626\n",
      "\t\tOut of 262144 , 13000 are done in 9.832900285720825\n",
      "\t\tOut of 262144 , 14000 are done in 9.858480453491211\n",
      "\t\tOut of 262144 , 15000 are done in 9.878722667694092\n",
      "\t\tOut of 262144 , 16000 are done in 9.92068600654602\n",
      "\t\tOut of 262144 , 17000 are done in 9.897151947021484\n",
      "\t\tOut of 262144 , 18000 are done in 9.906606674194336\n",
      "\t\tOut of 262144 , 19000 are done in 9.900397062301636\n",
      "\t\tOut of 262144 , 20000 are done in 9.928191900253296\n",
      "\t\tOut of 262144 , 21000 are done in 9.891126871109009\n",
      "\t\tOut of 262144 , 22000 are done in 9.897994041442871\n",
      "\t\tOut of 262144 , 23000 are done in 9.942753553390503\n",
      "\t\tOut of 262144 , 24000 are done in 9.874319314956665\n",
      "\t\tOut of 262144 , 25000 are done in 9.908018350601196\n",
      "\t\tOut of 262144 , 26000 are done in 9.924389600753784\n",
      "\t\tOut of 262144 , 27000 are done in 9.928274393081665\n",
      "\t\tOut of 262144 , 28000 are done in 9.884567975997925\n",
      "\t\tOut of 262144 , 29000 are done in 9.894985437393188\n",
      "\t\tOut of 262144 , 30000 are done in 9.904252052307129\n",
      "\t\tOut of 262144 , 31000 are done in 9.899073362350464\n",
      "\t\tOut of 262144 , 32000 are done in 9.85692310333252\n",
      "\t\tOut of 262144 , 33000 are done in 9.897213697433472\n",
      "\t\tOut of 262144 , 34000 are done in 9.919435977935791\n",
      "\t\tOut of 262144 , 35000 are done in 9.948363542556763\n",
      "\t\tOut of 262144 , 36000 are done in 9.971070766448975\n",
      "\t\tOut of 262144 , 37000 are done in 9.993573904037476\n",
      "\t\tOut of 262144 , 38000 are done in 9.946362972259521\n",
      "\t\tOut of 262144 , 39000 are done in 9.960416078567505\n",
      "\t\tOut of 262144 , 40000 are done in 9.94927167892456\n",
      "\t\tOut of 262144 , 41000 are done in 9.883752584457397\n",
      "\t\tOut of 262144 , 42000 are done in 9.964969158172607\n",
      "\t\tOut of 262144 , 43000 are done in 9.920248031616211\n",
      "\t\tOut of 262144 , 44000 are done in 9.923640251159668\n",
      "\t\tOut of 262144 , 45000 are done in 9.947338819503784\n",
      "\t\tOut of 262144 , 46000 are done in 9.945746660232544\n",
      "\t\tOut of 262144 , 47000 are done in 9.913545370101929\n",
      "\t\tOut of 262144 , 48000 are done in 9.914090633392334\n",
      "\t\tOut of 262144 , 49000 are done in 9.916147470474243\n",
      "\t\tOut of 262144 , 50000 are done in 9.963337182998657\n",
      "\t\tOut of 262144 , 51000 are done in 9.93828296661377\n",
      "\t\tOut of 262144 , 52000 are done in 9.96804141998291\n",
      "\t\tOut of 262144 , 53000 are done in 9.930915117263794\n",
      "\t\tOut of 262144 , 54000 are done in 9.9487624168396\n",
      "\t\tOut of 262144 , 55000 are done in 9.901021957397461\n",
      "\t\tOut of 262144 , 56000 are done in 9.962680578231812\n",
      "\t\tOut of 262144 , 57000 are done in 9.984368085861206\n",
      "\t\tOut of 262144 , 58000 are done in 9.929468154907227\n",
      "\t\tOut of 262144 , 59000 are done in 9.959689140319824\n",
      "\t\tOut of 262144 , 60000 are done in 9.95376467704773\n",
      "\t\tOut of 262144 , 61000 are done in 9.96760106086731\n",
      "\t\tOut of 262144 , 62000 are done in 9.951521158218384\n",
      "\t\tOut of 262144 , 63000 are done in 9.93776273727417\n",
      "\t\tOut of 262144 , 64000 are done in 9.963475227355957\n",
      "\t\tOut of 262144 , 65000 are done in 9.973903894424438\n",
      "\t\tOut of 262144 , 66000 are done in 9.895292520523071\n",
      "\t\tOut of 262144 , 67000 are done in 9.927479267120361\n",
      "\t\tOut of 262144 , 68000 are done in 9.930611848831177\n",
      "\t\tOut of 262144 , 69000 are done in 9.970732927322388\n",
      "\t\tOut of 262144 , 70000 are done in 9.900291442871094\n",
      "\t\tOut of 262144 , 71000 are done in 9.95681118965149\n",
      "\t\tOut of 262144 , 72000 are done in 9.962400913238525\n",
      "\t\tOut of 262144 , 73000 are done in 9.938310861587524\n",
      "\t\tOut of 262144 , 74000 are done in 9.924169063568115\n",
      "\t\tOut of 262144 , 75000 are done in 9.949338912963867\n"
     ]
    }
   ],
   "source": [
    "\n",
    "top_patients_dict = top_voxels_predict(top_patients_dict,LUNA_model_v3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['243038f7bb7787497c59bc17f04c6ed9'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_patients_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
