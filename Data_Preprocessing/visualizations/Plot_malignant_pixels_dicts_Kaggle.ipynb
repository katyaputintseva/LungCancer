{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def top_patients(NUM_patients=1,MODEL='feature_matrix_model2_stage1.csv'):\n",
    "    df = pd.read_csv(MODEL).sort_values(['max_malig'],ascending=[False])\n",
    "    top_patients_dict = {}\n",
    "    for i in range(NUM_patients):\n",
    "        \n",
    "        patient = df.iloc[i]['Unnamed: 0'][:-4]\n",
    "        top_patients_dict[patient] = {}\n",
    "        \n",
    "        malignancy = df.iloc[i]['max_malig']\n",
    "        top_patients_dict[patient]['max_malig'] = malignancy\n",
    "        \n",
    "        print ('Patient',i+1,':\\t',patient,'\\nMalignancy',i+1,':\\t',malignancy)\n",
    "        \n",
    "        with open('./LUNA_model_v2/dict_top_patients.pickle', 'wb') as handle:\n",
    "            pickle.dump(top_patients_dict,handle,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print ('\\tDictionary SAVED for..',patient)\n",
    "        \n",
    "    return top_patients_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 1 :\t 07bca4290a2530091ce1d5f200d9d526 \n",
      "Malignancy 1 :\t 0.534115552902\n",
      "\tDictionary SAVED for.. 07bca4290a2530091ce1d5f200d9d526\n"
     ]
    }
   ],
   "source": [
    "\n",
    "top_patients_dict = top_patients()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.models import load_model\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.15\n",
    "set_session(tf.Session(config=config))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def top_patients_predict(top_patients_DICT,MODEL,TOP=1):\n",
    "    top_patients_dict = deepcopy(top_patients_DICT)\n",
    "    for patient in top_patients_dict.keys():\n",
    "        print ('Patient..',patient)\n",
    "        patient_load = np.load('../data/stage1_voxels_mask/'+patient+'.npz')\n",
    "        voxels = patient_load['vox']\n",
    "        print ('\\tNumber of voxels to predict..',voxels.shape[0])\n",
    "        \n",
    "        preds = np.array(MODEL.predict(x=voxels,batch_size=5))\n",
    "        top_patients_dict[patient]['preds'] = preds\n",
    "        np.save('./LUNA_model_v2/preds_'+patient+'.npy',preds)\n",
    "        print ('\\tVoxels predicted..',len(preds))\n",
    "        \n",
    "        top_ixs = np.argsort(preds[0],axis=0)[-TOP:]\n",
    "        top_ixs = [i[0] for i in top_ixs]\n",
    "        top_patients_dict[patient]['top_ixs'] = top_ixs\n",
    "        print ('\\tNumber of top voxels for visualization..',len(top_ixs))\n",
    "        \n",
    "        top_patients_dict[patient]['top_voxels'] = np.vstack([voxels[i] for i in top_ixs])\n",
    "        with open('./LUNA_model_v2/dict_top_patients_predict.pickle', 'wb') as handle:\n",
    "            pickle.dump(top_patients_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print ('\\tDictionary SAVED for..',patient)\n",
    "        \n",
    "    return top_patients_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.5/site-packages/keras/engine/topology.py:1206: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  return cls(**config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient.. 07bca4290a2530091ce1d5f200d9d526\n",
      "\tNumber of voxels to predict.. 472\n",
      "\tVoxels predicted.. 4\n",
      "\tNumber of top voxels for visualization.. 1\n",
      "\tDictionary SAVED for.. 07bca4290a2530091ce1d5f200d9d526\n"
     ]
    }
   ],
   "source": [
    "\n",
    "LUNA_model_v2 = load_model('../LungCancer/Models/LUNA_model_v2.h5')\n",
    "top_patients_dict = top_patients_predict(top_patients_dict,LUNA_model_v2,TOP=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def top_voxels_predict(top_patients_DICT,MODEL):\n",
    "    top_patients_dict = deepcopy(top_patients_DICT)\n",
    "    for patient in top_patients_dict.keys():\n",
    "        print ('Patient..',patient)\n",
    "        \n",
    "        top_voxels = top_patients_dict[patient]['top_voxels']\n",
    "        \n",
    "        for i in range(top_voxels.shape[0]):\n",
    "            print ('\\tPredicting voxel',i+1)\n",
    "            start = time.time()\n",
    "            \n",
    "            voxel = np.squeeze(top_voxels[i])\n",
    "            count = 0\n",
    "            preds_top_voxels = []\n",
    "            \n",
    "            for e in np.nditer(voxel,op_flags=['readwrite']):\n",
    "                e_original = e.copy()\n",
    "                e[...] = 0\n",
    "                preds = MODEL.predict(x=np.expand_dims(np.expand_dims(voxel,axis=0),axis=0),batch_size=1)\n",
    "                preds = [p[0][0] for p in preds]\n",
    "                preds_top_voxels.append(preds)\n",
    "                e[...] = e_original\n",
    "                count +=1\n",
    "                if count%1000==0:\n",
    "                    print ('\\t\\tOut of',64*64*64,',',count,'are done in',time.time()-start)\n",
    "                    start = time.time()\n",
    "            top_patients_dict[patient][i+1] = preds_top_voxels\n",
    "        \n",
    "        with open('./LUNA_model_v2/dict_top_voxels_predict.pickle', 'wb') as handle:\n",
    "            pickle.dump(top_patients_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print ('\\tDictionary SAVED for..',patient)\n",
    "        \n",
    "    return top_patients_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient.. 07bca4290a2530091ce1d5f200d9d526\n",
      "\tPredicting voxel 1\n",
      "\t\tOut of 262144 , 1000 are done in 18.374861478805542\n",
      "\t\tOut of 262144 , 2000 are done in 18.594287872314453\n",
      "\t\tOut of 262144 , 3000 are done in 19.076767683029175\n",
      "\t\tOut of 262144 , 4000 are done in 18.622472763061523\n",
      "\t\tOut of 262144 , 5000 are done in 18.63280749320984\n",
      "\t\tOut of 262144 , 6000 are done in 22.29219388961792\n",
      "\t\tOut of 262144 , 7000 are done in 22.623486518859863\n",
      "\t\tOut of 262144 , 8000 are done in 22.68666911125183\n",
      "\t\tOut of 262144 , 9000 are done in 18.847500801086426\n",
      "\t\tOut of 262144 , 10000 are done in 18.386873722076416\n",
      "\t\tOut of 262144 , 11000 are done in 18.831682920455933\n",
      "\t\tOut of 262144 , 12000 are done in 18.46752667427063\n",
      "\t\tOut of 262144 , 13000 are done in 18.457491397857666\n",
      "\t\tOut of 262144 , 14000 are done in 18.535998106002808\n",
      "\t\tOut of 262144 , 15000 are done in 18.4964599609375\n",
      "\t\tOut of 262144 , 16000 are done in 18.407580852508545\n",
      "\t\tOut of 262144 , 17000 are done in 18.45382070541382\n",
      "\t\tOut of 262144 , 18000 are done in 18.4188129901886\n",
      "\t\tOut of 262144 , 19000 are done in 18.48179316520691\n",
      "\t\tOut of 262144 , 20000 are done in 18.349506378173828\n",
      "\t\tOut of 262144 , 21000 are done in 18.395404815673828\n",
      "\t\tOut of 262144 , 22000 are done in 18.454571962356567\n",
      "\t\tOut of 262144 , 23000 are done in 18.441851377487183\n",
      "\t\tOut of 262144 , 24000 are done in 18.478872060775757\n",
      "\t\tOut of 262144 , 25000 are done in 18.499918460845947\n",
      "\t\tOut of 262144 , 26000 are done in 18.442758560180664\n",
      "\t\tOut of 262144 , 27000 are done in 18.434252977371216\n",
      "\t\tOut of 262144 , 28000 are done in 18.466477394104004\n",
      "\t\tOut of 262144 , 29000 are done in 18.621506452560425\n",
      "\t\tOut of 262144 , 30000 are done in 18.495465993881226\n",
      "\t\tOut of 262144 , 31000 are done in 18.548197269439697\n",
      "\t\tOut of 262144 , 32000 are done in 18.436769008636475\n",
      "\t\tOut of 262144 , 33000 are done in 18.848374366760254\n",
      "\t\tOut of 262144 , 34000 are done in 18.491449117660522\n",
      "\t\tOut of 262144 , 35000 are done in 18.504779815673828\n",
      "\t\tOut of 262144 , 36000 are done in 18.470793962478638\n",
      "\t\tOut of 262144 , 37000 are done in 18.5903000831604\n",
      "\t\tOut of 262144 , 38000 are done in 18.541234254837036\n",
      "\t\tOut of 262144 , 39000 are done in 18.619502782821655\n",
      "\t\tOut of 262144 , 40000 are done in 18.530355215072632\n",
      "\t\tOut of 262144 , 41000 are done in 18.43717932701111\n",
      "\t\tOut of 262144 , 42000 are done in 18.579383373260498\n",
      "\t\tOut of 262144 , 43000 are done in 18.434642553329468\n",
      "\t\tOut of 262144 , 44000 are done in 18.79594922065735\n",
      "\t\tOut of 262144 , 45000 are done in 18.518832445144653\n",
      "\t\tOut of 262144 , 46000 are done in 18.546056509017944\n",
      "\t\tOut of 262144 , 47000 are done in 18.481667518615723\n",
      "\t\tOut of 262144 , 48000 are done in 18.48251962661743\n",
      "\t\tOut of 262144 , 49000 are done in 18.512301445007324\n",
      "\t\tOut of 262144 , 50000 are done in 18.48804783821106\n",
      "\t\tOut of 262144 , 51000 are done in 18.562910795211792\n",
      "\t\tOut of 262144 , 52000 are done in 18.54813861846924\n",
      "\t\tOut of 262144 , 53000 are done in 18.514201879501343\n",
      "\t\tOut of 262144 , 54000 are done in 18.541253805160522\n",
      "\t\tOut of 262144 , 55000 are done in 18.508326768875122\n",
      "\t\tOut of 262144 , 56000 are done in 18.49415946006775\n",
      "\t\tOut of 262144 , 57000 are done in 18.495710611343384\n",
      "\t\tOut of 262144 , 58000 are done in 18.606492042541504\n",
      "\t\tOut of 262144 , 59000 are done in 18.672786474227905\n",
      "\t\tOut of 262144 , 60000 are done in 18.52552103996277\n",
      "\t\tOut of 262144 , 61000 are done in 18.639159440994263\n",
      "\t\tOut of 262144 , 62000 are done in 18.563228607177734\n",
      "\t\tOut of 262144 , 63000 are done in 18.574822664260864\n",
      "\t\tOut of 262144 , 64000 are done in 18.482255697250366\n",
      "\t\tOut of 262144 , 65000 are done in 18.548061847686768\n",
      "\t\tOut of 262144 , 66000 are done in 18.620688915252686\n",
      "\t\tOut of 262144 , 67000 are done in 19.466374397277832\n",
      "\t\tOut of 262144 , 68000 are done in 18.49115753173828\n",
      "\t\tOut of 262144 , 69000 are done in 18.650886058807373\n",
      "\t\tOut of 262144 , 70000 are done in 18.52271795272827\n",
      "\t\tOut of 262144 , 71000 are done in 18.534619569778442\n",
      "\t\tOut of 262144 , 72000 are done in 18.62346053123474\n",
      "\t\tOut of 262144 , 73000 are done in 18.51360845565796\n",
      "\t\tOut of 262144 , 74000 are done in 18.494385242462158\n",
      "\t\tOut of 262144 , 75000 are done in 18.421868085861206\n",
      "\t\tOut of 262144 , 76000 are done in 18.55145573616028\n",
      "\t\tOut of 262144 , 77000 are done in 18.518930196762085\n",
      "\t\tOut of 262144 , 78000 are done in 18.597108125686646\n",
      "\t\tOut of 262144 , 79000 are done in 18.508906364440918\n",
      "\t\tOut of 262144 , 80000 are done in 18.615135669708252\n",
      "\t\tOut of 262144 , 81000 are done in 18.489833116531372\n",
      "\t\tOut of 262144 , 82000 are done in 18.566608667373657\n",
      "\t\tOut of 262144 , 83000 are done in 18.590180158615112\n",
      "\t\tOut of 262144 , 84000 are done in 18.661038398742676\n",
      "\t\tOut of 262144 , 85000 are done in 18.57047414779663\n",
      "\t\tOut of 262144 , 86000 are done in 18.58293318748474\n",
      "\t\tOut of 262144 , 87000 are done in 18.597015857696533\n",
      "\t\tOut of 262144 , 88000 are done in 18.746177911758423\n",
      "\t\tOut of 262144 , 89000 are done in 18.596652269363403\n",
      "\t\tOut of 262144 , 90000 are done in 18.62192726135254\n",
      "\t\tOut of 262144 , 91000 are done in 18.643345832824707\n",
      "\t\tOut of 262144 , 92000 are done in 18.514354944229126\n",
      "\t\tOut of 262144 , 93000 are done in 18.53805160522461\n",
      "\t\tOut of 262144 , 94000 are done in 18.64501166343689\n",
      "\t\tOut of 262144 , 95000 are done in 18.5327889919281\n",
      "\t\tOut of 262144 , 96000 are done in 18.512636184692383\n",
      "\t\tOut of 262144 , 97000 are done in 18.61940836906433\n",
      "\t\tOut of 262144 , 98000 are done in 18.572754383087158\n",
      "\t\tOut of 262144 , 99000 are done in 18.561973333358765\n",
      "\t\tOut of 262144 , 100000 are done in 18.576984643936157\n",
      "\t\tOut of 262144 , 101000 are done in 18.589428901672363\n",
      "\t\tOut of 262144 , 102000 are done in 18.55694007873535\n",
      "\t\tOut of 262144 , 103000 are done in 18.725274085998535\n",
      "\t\tOut of 262144 , 104000 are done in 18.526572227478027\n",
      "\t\tOut of 262144 , 105000 are done in 18.391592025756836\n",
      "\t\tOut of 262144 , 106000 are done in 18.448566198349\n",
      "\t\tOut of 262144 , 107000 are done in 18.467281341552734\n",
      "\t\tOut of 262144 , 108000 are done in 18.57593584060669\n",
      "\t\tOut of 262144 , 109000 are done in 18.493074655532837\n",
      "\t\tOut of 262144 , 110000 are done in 18.542268753051758\n",
      "\t\tOut of 262144 , 111000 are done in 18.567118644714355\n",
      "\t\tOut of 262144 , 112000 are done in 18.4983491897583\n",
      "\t\tOut of 262144 , 113000 are done in 18.62039589881897\n",
      "\t\tOut of 262144 , 114000 are done in 18.518763780593872\n",
      "\t\tOut of 262144 , 115000 are done in 18.500426530838013\n",
      "\t\tOut of 262144 , 116000 are done in 18.53730297088623\n",
      "\t\tOut of 262144 , 117000 are done in 18.545743465423584\n",
      "\t\tOut of 262144 , 118000 are done in 18.60481309890747\n",
      "\t\tOut of 262144 , 119000 are done in 18.463745594024658\n",
      "\t\tOut of 262144 , 120000 are done in 18.62188696861267\n",
      "\t\tOut of 262144 , 121000 are done in 18.52099061012268\n",
      "\t\tOut of 262144 , 122000 are done in 16.03075408935547\n",
      "\t\tOut of 262144 , 123000 are done in 9.946464538574219\n",
      "\t\tOut of 262144 , 124000 are done in 9.957365036010742\n",
      "\t\tOut of 262144 , 125000 are done in 9.905892372131348\n",
      "\t\tOut of 262144 , 126000 are done in 9.903172492980957\n",
      "\t\tOut of 262144 , 127000 are done in 9.917214155197144\n",
      "\t\tOut of 262144 , 128000 are done in 9.925785303115845\n",
      "\t\tOut of 262144 , 129000 are done in 9.83910846710205\n",
      "\t\tOut of 262144 , 130000 are done in 9.904113054275513\n",
      "\t\tOut of 262144 , 131000 are done in 9.910378694534302\n",
      "\t\tOut of 262144 , 132000 are done in 9.91188097000122\n",
      "\t\tOut of 262144 , 133000 are done in 9.91728401184082\n",
      "\t\tOut of 262144 , 134000 are done in 9.896031856536865\n",
      "\t\tOut of 262144 , 135000 are done in 9.91935396194458\n",
      "\t\tOut of 262144 , 136000 are done in 9.871838331222534\n",
      "\t\tOut of 262144 , 137000 are done in 9.93853211402893\n",
      "\t\tOut of 262144 , 138000 are done in 9.904571294784546\n",
      "\t\tOut of 262144 , 139000 are done in 9.93839716911316\n",
      "\t\tOut of 262144 , 140000 are done in 9.956450700759888\n",
      "\t\tOut of 262144 , 141000 are done in 9.925353527069092\n",
      "\t\tOut of 262144 , 142000 are done in 9.883139610290527\n",
      "\t\tOut of 262144 , 143000 are done in 9.88304877281189\n",
      "\t\tOut of 262144 , 144000 are done in 9.960866689682007\n",
      "\t\tOut of 262144 , 145000 are done in 9.876280307769775\n",
      "\t\tOut of 262144 , 146000 are done in 9.881047248840332\n",
      "\t\tOut of 262144 , 147000 are done in 9.882140874862671\n",
      "\t\tOut of 262144 , 148000 are done in 9.917607307434082\n",
      "\t\tOut of 262144 , 149000 are done in 9.855617761611938\n",
      "\t\tOut of 262144 , 150000 are done in 9.892170906066895\n",
      "\t\tOut of 262144 , 151000 are done in 9.87900710105896\n",
      "\t\tOut of 262144 , 152000 are done in 9.877772569656372\n",
      "\t\tOut of 262144 , 153000 are done in 9.858609437942505\n",
      "\t\tOut of 262144 , 154000 are done in 9.958134651184082\n",
      "\t\tOut of 262144 , 155000 are done in 9.895071029663086\n",
      "\t\tOut of 262144 , 156000 are done in 9.90565299987793\n",
      "\t\tOut of 262144 , 157000 are done in 9.884620666503906\n",
      "\t\tOut of 262144 , 158000 are done in 9.869638204574585\n",
      "\t\tOut of 262144 , 159000 are done in 9.8954496383667\n",
      "\t\tOut of 262144 , 160000 are done in 10.013267517089844\n",
      "\t\tOut of 262144 , 161000 are done in 9.952244281768799\n",
      "\t\tOut of 262144 , 162000 are done in 9.91287612915039\n",
      "\t\tOut of 262144 , 163000 are done in 9.84732460975647\n",
      "\t\tOut of 262144 , 164000 are done in 9.872421503067017\n",
      "\t\tOut of 262144 , 165000 are done in 9.907255411148071\n",
      "\t\tOut of 262144 , 166000 are done in 9.938374042510986\n",
      "\t\tOut of 262144 , 167000 are done in 9.904049396514893\n",
      "\t\tOut of 262144 , 168000 are done in 9.890500545501709\n",
      "\t\tOut of 262144 , 169000 are done in 9.894033670425415\n",
      "\t\tOut of 262144 , 170000 are done in 9.866195917129517\n",
      "\t\tOut of 262144 , 171000 are done in 9.889938354492188\n",
      "\t\tOut of 262144 , 172000 are done in 9.90702772140503\n",
      "\t\tOut of 262144 , 173000 are done in 9.92005205154419\n",
      "\t\tOut of 262144 , 174000 are done in 9.887287139892578\n",
      "\t\tOut of 262144 , 175000 are done in 9.91503095626831\n",
      "\t\tOut of 262144 , 176000 are done in 9.944413423538208\n",
      "\t\tOut of 262144 , 177000 are done in 9.951486587524414\n",
      "\t\tOut of 262144 , 178000 are done in 9.851711511611938\n",
      "\t\tOut of 262144 , 179000 are done in 9.943402290344238\n",
      "\t\tOut of 262144 , 180000 are done in 9.947203159332275\n",
      "\t\tOut of 262144 , 181000 are done in 9.887903213500977\n",
      "\t\tOut of 262144 , 182000 are done in 9.946630477905273\n",
      "\t\tOut of 262144 , 183000 are done in 9.878525018692017\n",
      "\t\tOut of 262144 , 184000 are done in 9.864432573318481\n",
      "\t\tOut of 262144 , 185000 are done in 9.91208529472351\n",
      "\t\tOut of 262144 , 186000 are done in 9.863166809082031\n",
      "\t\tOut of 262144 , 187000 are done in 9.895872116088867\n",
      "\t\tOut of 262144 , 188000 are done in 9.902769804000854\n",
      "\t\tOut of 262144 , 189000 are done in 9.919878244400024\n",
      "\t\tOut of 262144 , 190000 are done in 9.897207975387573\n",
      "\t\tOut of 262144 , 191000 are done in 9.971427202224731\n",
      "\t\tOut of 262144 , 192000 are done in 9.853477239608765\n",
      "\t\tOut of 262144 , 193000 are done in 9.868473768234253\n",
      "\t\tOut of 262144 , 194000 are done in 9.855947017669678\n",
      "\t\tOut of 262144 , 195000 are done in 9.909788846969604\n",
      "\t\tOut of 262144 , 196000 are done in 9.887596607208252\n",
      "\t\tOut of 262144 , 197000 are done in 9.835528373718262\n",
      "\t\tOut of 262144 , 198000 are done in 9.867508172988892\n",
      "\t\tOut of 262144 , 199000 are done in 9.914917945861816\n",
      "\t\tOut of 262144 , 200000 are done in 9.879134178161621\n",
      "\t\tOut of 262144 , 201000 are done in 9.850029945373535\n",
      "\t\tOut of 262144 , 202000 are done in 9.851981401443481\n",
      "\t\tOut of 262144 , 203000 are done in 9.877933740615845\n",
      "\t\tOut of 262144 , 204000 are done in 9.867217779159546\n",
      "\t\tOut of 262144 , 205000 are done in 9.86457085609436\n",
      "\t\tOut of 262144 , 206000 are done in 9.854384660720825\n",
      "\t\tOut of 262144 , 207000 are done in 9.898278951644897\n",
      "\t\tOut of 262144 , 208000 are done in 9.849461078643799\n",
      "\t\tOut of 262144 , 209000 are done in 9.908207178115845\n",
      "\t\tOut of 262144 , 210000 are done in 9.899899959564209\n",
      "\t\tOut of 262144 , 211000 are done in 9.839436769485474\n",
      "\t\tOut of 262144 , 212000 are done in 9.865466117858887\n",
      "\t\tOut of 262144 , 213000 are done in 9.836426496505737\n",
      "\t\tOut of 262144 , 214000 are done in 9.889535665512085\n",
      "\t\tOut of 262144 , 215000 are done in 9.866467475891113\n",
      "\t\tOut of 262144 , 216000 are done in 9.878335237503052\n",
      "\t\tOut of 262144 , 217000 are done in 9.852240562438965\n",
      "\t\tOut of 262144 , 218000 are done in 9.85051679611206\n",
      "\t\tOut of 262144 , 219000 are done in 9.873018741607666\n",
      "\t\tOut of 262144 , 220000 are done in 9.888936758041382\n",
      "\t\tOut of 262144 , 221000 are done in 9.924101829528809\n",
      "\t\tOut of 262144 , 222000 are done in 9.837313175201416\n",
      "\t\tOut of 262144 , 223000 are done in 9.883988618850708\n",
      "\t\tOut of 262144 , 224000 are done in 9.905752658843994\n",
      "\t\tOut of 262144 , 225000 are done in 9.983258485794067\n",
      "\t\tOut of 262144 , 226000 are done in 9.950516700744629\n",
      "\t\tOut of 262144 , 227000 are done in 9.917379379272461\n",
      "\t\tOut of 262144 , 228000 are done in 9.923902034759521\n",
      "\t\tOut of 262144 , 229000 are done in 9.832221508026123\n",
      "\t\tOut of 262144 , 230000 are done in 9.906306982040405\n",
      "\t\tOut of 262144 , 231000 are done in 9.895593643188477\n",
      "\t\tOut of 262144 , 232000 are done in 9.859720468521118\n",
      "\t\tOut of 262144 , 233000 are done in 9.871306657791138\n",
      "\t\tOut of 262144 , 234000 are done in 9.900131702423096\n",
      "\t\tOut of 262144 , 235000 are done in 9.87612271308899\n",
      "\t\tOut of 262144 , 236000 are done in 9.851071119308472\n",
      "\t\tOut of 262144 , 237000 are done in 9.867542743682861\n",
      "\t\tOut of 262144 , 238000 are done in 9.856330156326294\n",
      "\t\tOut of 262144 , 239000 are done in 10.413108587265015\n",
      "\t\tOut of 262144 , 240000 are done in 9.862951040267944\n",
      "\t\tOut of 262144 , 241000 are done in 10.890000104904175\n",
      "\t\tOut of 262144 , 242000 are done in 10.258511543273926\n",
      "\t\tOut of 262144 , 243000 are done in 10.431535959243774\n",
      "\t\tOut of 262144 , 244000 are done in 9.864288330078125\n",
      "\t\tOut of 262144 , 245000 are done in 9.96983027458191\n",
      "\t\tOut of 262144 , 246000 are done in 9.916304588317871\n",
      "\t\tOut of 262144 , 247000 are done in 9.879150867462158\n",
      "\t\tOut of 262144 , 248000 are done in 9.900191068649292\n",
      "\t\tOut of 262144 , 249000 are done in 10.770293712615967\n",
      "\t\tOut of 262144 , 250000 are done in 9.832884788513184\n",
      "\t\tOut of 262144 , 251000 are done in 9.874873161315918\n",
      "\t\tOut of 262144 , 252000 are done in 9.819407224655151\n",
      "\t\tOut of 262144 , 253000 are done in 10.008973598480225\n",
      "\t\tOut of 262144 , 254000 are done in 10.499241590499878\n",
      "\t\tOut of 262144 , 255000 are done in 9.871350049972534\n",
      "\t\tOut of 262144 , 256000 are done in 10.88044810295105\n",
      "\t\tOut of 262144 , 257000 are done in 10.14804482460022\n",
      "\t\tOut of 262144 , 258000 are done in 10.37702465057373\n",
      "\t\tOut of 262144 , 259000 are done in 9.993009090423584\n",
      "\t\tOut of 262144 , 260000 are done in 10.706665754318237\n",
      "\t\tOut of 262144 , 261000 are done in 9.84098196029663\n",
      "\t\tOut of 262144 , 262000 are done in 9.934151887893677\n",
      "\tDictionary SAVED for.. 07bca4290a2530091ce1d5f200d9d526\n"
     ]
    }
   ],
   "source": [
    "\n",
    "top_patients_dict = top_voxels_predict(top_patients_dict,LUNA_model_v2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
