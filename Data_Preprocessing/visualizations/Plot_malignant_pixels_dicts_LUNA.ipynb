{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def top_patients(NUM_patients=1,MODEL='model2_feature_matrix_luna.csv'):\n",
    "    df = pd.read_csv(MODEL).sort_values(['max_malig'],ascending=[False])\n",
    "    top_patients_dict = {}\n",
    "    for i in range(NUM_patients):\n",
    "        \n",
    "        patient = df.iloc[i]['Unnamed: 0']\n",
    "        top_patients_dict[int(patient)] = {}\n",
    "        \n",
    "        malignancy = df.iloc[i]['max_malig']\n",
    "        top_patients_dict[int(patient)]['max_malig'] = malignancy\n",
    "        \n",
    "        print ('Patient',i+1,':\\t',patient,'\\nMalignancy',i+1,':\\t',malignancy)\n",
    "        \n",
    "        with open('./LUNA_model_v2_LUNA/dict_top_patients.pickle', 'wb') as handle:\n",
    "            pickle.dump(top_patients_dict,handle,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print ('\\tDictionary SAVED for..',patient)\n",
    "        \n",
    "    return top_patients_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 1 :\t 472.0 \n",
      "Malignancy 1 :\t 0.533818006516\n",
      "\tDictionary SAVED for.. 472.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "top_patients_dict = top_patients()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_LUNA_patches(top_patients_DICT):\n",
    "    labels = []\n",
    "    num_patients = 0\n",
    "    \n",
    "    with open('../data/voxel_to_patient_dict.pickle', 'rb') as handle:\n",
    "        voxel_to_patient_dict = pickle.load(handle)\n",
    "\n",
    "    for directory in [d for d in os.listdir('../data/') if 'subset' in d]:\n",
    "        patients_by_dir = [f.replace('.mhd','') for f in os.listdir('../data/'+directory) if '.mhd' in f]\n",
    "        Xtrue = np.load('../data/LUNA_voxels/'+directory+'Xtrue.npy')\n",
    "        Xrandom = np.load('../data/LUNA_voxels/'+directory+'Xrandom.npy')\n",
    "        count={'true':0,'random':0}\n",
    "\n",
    "        for num, patient in enumerate(patients_by_dir):\n",
    "            num_patients += 1\n",
    "            array = []\n",
    "            try:\n",
    "\n",
    "                lowerBoundary = count['true']\n",
    "                upperBoundary = count['true'] + int(voxel_to_patient_dict[directory][patient]['true'])\n",
    "\n",
    "                if num_patients == list(top_patients_DICT.keys())[0]+1:\n",
    "                    print ('FOUND PATIENT',list(top_patients_DICT.keys())[0],'!_______________________')\n",
    "                    print ('\\tLower boundary for True is ',lowerBoundary)\n",
    "                    print ('\\tUpper boundary for True is ',upperBoundary)\n",
    "                    array.append(Xtrue[lowerBoundary:upperBoundary])\n",
    "                    labels.append(1)\n",
    "\n",
    "                count['true'] = upperBoundary\n",
    "\n",
    "            except:\n",
    "\n",
    "                labels.append(0)\n",
    "\n",
    "            lowerBoundary = count['random']\n",
    "            upperBoundary = count['random'] + int(voxel_to_patient_dict[directory][patient]['random'])\n",
    "\n",
    "            if num_patients == list(top_patients_DICT.keys())[0]+1:\n",
    "                print ('\\tLower boundary for Random is ',lowerBoundary)\n",
    "                print ('\\tUpper boundary for Random is ',upperBoundary)\n",
    "                array.append(Xrandom[lowerBoundary:upperBoundary])\n",
    "\n",
    "            count['random'] = upperBoundary\n",
    "\n",
    "            if num_patients == list(top_patients_dict.keys())[0]+1:\n",
    "                break\n",
    "        if num_patients == list(top_patients_dict.keys())[0]+1:\n",
    "            break\n",
    "\n",
    "    array = np.vstack(array)\n",
    "    print ('Array shape before expansion',array.shape)\n",
    "    array = np.expand_dims(array,1)\n",
    "    array = (array+1000.)/1400.\n",
    "    array = np.clip(array,0,1)\n",
    "    print ('Array shape',array.shape)\n",
    "    \n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.models import load_model\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.15\n",
    "set_session(tf.Session(config=config))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def top_patients_predict(top_patients_DICT,MODEL,TOP=1):\n",
    "    top_patients_dict = deepcopy(top_patients_DICT)\n",
    "    for patient in top_patients_dict.keys():\n",
    "        print ('Patient..',patient)\n",
    "        voxels = get_LUNA_patches(top_patients_dict)\n",
    "        print ('\\tNumber of voxels to predict..',voxels.shape[0])\n",
    "        \n",
    "        preds = np.array(MODEL.predict(x=voxels,batch_size=5))\n",
    "        top_patients_dict[patient]['preds'] = preds\n",
    "        np.save('./LUNA_model_v2/preds_'+str(int(patient))+'.npy',preds)\n",
    "        print ('\\tVoxels predicted..',len(preds))\n",
    "        \n",
    "        top_ixs = np.argsort(preds[0],axis=0)[-TOP:]\n",
    "        top_ixs = [i[0] for i in top_ixs]\n",
    "        top_patients_dict[patient]['top_ixs'] = top_ixs\n",
    "        print ('\\tNumber of top voxels for visualization..',len(top_ixs))\n",
    "        \n",
    "        top_patients_dict[patient]['top_voxels'] = np.vstack([voxels[i] for i in top_ixs])\n",
    "        with open('./LUNA_model_v2_LUNA/dict_top_patients_predict.pickle', 'wb') as handle:\n",
    "            pickle.dump(top_patients_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print ('\\tDictionary SAVED for..',patient)\n",
    "        \n",
    "    return top_patients_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.5/site-packages/keras/engine/topology.py:1206: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  return cls(**config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient.. 472\n",
      "FOUND PATIENT 472 !_______________________\n",
      "\tLower boundary for True is  192\n",
      "\tUpper boundary for True is  204\n",
      "\tLower boundary for Random is  252\n",
      "\tUpper boundary for Random is  264\n",
      "Array shape before expansion (24, 64, 64, 64)\n",
      "Array shape (24, 1, 64, 64, 64)\n",
      "\tNumber of voxels to predict.. 24\n",
      "\tVoxels predicted.. 4\n",
      "\tNumber of top voxels for visualization.. 1\n",
      "\tDictionary SAVED for.. 472\n"
     ]
    }
   ],
   "source": [
    "\n",
    "LUNA_model_v2 = load_model('../LungCancer/Models/LUNA_model_v2.h5')\n",
    "top_patients_dict = top_patients_predict(top_patients_dict,LUNA_model_v2,TOP=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def top_voxels_predict(top_patients_DICT,MODEL):\n",
    "    top_patients_dict = deepcopy(top_patients_DICT)\n",
    "    for patient in top_patients_dict.keys():\n",
    "        print ('Patient..',patient)\n",
    "        \n",
    "        top_voxels = top_patients_dict[patient]['top_voxels']\n",
    "        \n",
    "        for i in range(top_voxels.shape[0]):\n",
    "            print ('\\tPredicting voxel',i+1)\n",
    "            start = time.time()\n",
    "            \n",
    "            voxel = np.squeeze(top_voxels[i])\n",
    "            count = 0\n",
    "            preds_top_voxels = []\n",
    "            \n",
    "            for e in np.nditer(voxel,op_flags=['readwrite']):\n",
    "                e_original = e.copy()\n",
    "                e[...] = 0\n",
    "                preds = MODEL.predict(x=np.expand_dims(np.expand_dims(voxel,axis=0),axis=0),batch_size=1)\n",
    "                preds = [p[0][0] for p in preds]\n",
    "                preds_top_voxels.append(preds)\n",
    "                e[...] = e_original\n",
    "                count +=1\n",
    "                if count%1000==0:\n",
    "                    print ('\\t\\tOut of',64*64*64,',',count,'are done in',time.time()-start)\n",
    "                    start = time.time()\n",
    "            top_patients_dict[patient][i+1] = preds_top_voxels\n",
    "        \n",
    "        with open('./LUNA_model_v2_LUNA/dict_top_voxels_predict.pickle', 'wb') as handle:\n",
    "            pickle.dump(top_patients_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print ('\\tDictionary SAVED for..',patient)\n",
    "        \n",
    "    return top_patients_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient.. 472\n",
      "\tPredicting voxel 1\n",
      "\t\tOut of 262144 , 1000 are done in 23.59552240371704\n",
      "\t\tOut of 262144 , 2000 are done in 20.02323031425476\n",
      "\t\tOut of 262144 , 3000 are done in 23.76174759864807\n",
      "\t\tOut of 262144 , 4000 are done in 23.23139214515686\n",
      "\t\tOut of 262144 , 5000 are done in 23.226093292236328\n",
      "\t\tOut of 262144 , 6000 are done in 20.140151977539062\n",
      "\t\tOut of 262144 , 7000 are done in 19.859532594680786\n",
      "\t\tOut of 262144 , 8000 are done in 22.237860679626465\n",
      "\t\tOut of 262144 , 9000 are done in 19.792877674102783\n",
      "\t\tOut of 262144 , 10000 are done in 23.052852392196655\n",
      "\t\tOut of 262144 , 11000 are done in 23.854332447052002\n",
      "\t\tOut of 262144 , 12000 are done in 21.5396990776062\n",
      "\t\tOut of 262144 , 13000 are done in 22.092008590698242\n",
      "\t\tOut of 262144 , 14000 are done in 20.085764169692993\n",
      "\t\tOut of 262144 , 15000 are done in 19.96256995201111\n",
      "\t\tOut of 262144 , 16000 are done in 23.306487798690796\n",
      "\t\tOut of 262144 , 17000 are done in 20.47577214241028\n",
      "\t\tOut of 262144 , 18000 are done in 22.030323266983032\n",
      "\t\tOut of 262144 , 19000 are done in 20.97665786743164\n",
      "\t\tOut of 262144 , 20000 are done in 19.209470748901367\n",
      "\t\tOut of 262144 , 21000 are done in 24.089467763900757\n",
      "\t\tOut of 262144 , 22000 are done in 23.80278778076172\n",
      "\t\tOut of 262144 , 23000 are done in 22.377588510513306\n",
      "\t\tOut of 262144 , 24000 are done in 21.028974533081055\n",
      "\t\tOut of 262144 , 25000 are done in 20.091822624206543\n",
      "\t\tOut of 262144 , 26000 are done in 22.240896463394165\n",
      "\t\tOut of 262144 , 27000 are done in 20.427206993103027\n",
      "\t\tOut of 262144 , 28000 are done in 20.609410524368286\n",
      "\t\tOut of 262144 , 29000 are done in 19.908635139465332\n",
      "\t\tOut of 262144 , 30000 are done in 22.33796763420105\n",
      "\t\tOut of 262144 , 31000 are done in 18.653831481933594\n",
      "\t\tOut of 262144 , 32000 are done in 19.865761280059814\n",
      "\t\tOut of 262144 , 33000 are done in 21.682144165039062\n",
      "\t\tOut of 262144 , 34000 are done in 20.876476049423218\n",
      "\t\tOut of 262144 , 35000 are done in 19.20598077774048\n",
      "\t\tOut of 262144 , 36000 are done in 20.094087600708008\n",
      "\t\tOut of 262144 , 37000 are done in 23.419299364089966\n",
      "\t\tOut of 262144 , 38000 are done in 18.91204833984375\n",
      "\t\tOut of 262144 , 39000 are done in 19.948652982711792\n",
      "\t\tOut of 262144 , 40000 are done in 23.674257040023804\n",
      "\t\tOut of 262144 , 41000 are done in 20.562822818756104\n",
      "\t\tOut of 262144 , 42000 are done in 21.392113208770752\n",
      "\t\tOut of 262144 , 43000 are done in 21.550288200378418\n",
      "\t\tOut of 262144 , 44000 are done in 18.667311429977417\n",
      "\t\tOut of 262144 , 45000 are done in 18.82315707206726\n",
      "\t\tOut of 262144 , 46000 are done in 21.3014714717865\n",
      "\t\tOut of 262144 , 47000 are done in 17.63304090499878\n",
      "\t\tOut of 262144 , 48000 are done in 20.064202308654785\n",
      "\t\tOut of 262144 , 49000 are done in 24.17073345184326\n",
      "\t\tOut of 262144 , 50000 are done in 20.531495332717896\n",
      "\t\tOut of 262144 , 51000 are done in 22.552709817886353\n",
      "\t\tOut of 262144 , 52000 are done in 19.641460180282593\n",
      "\t\tOut of 262144 , 53000 are done in 22.522695064544678\n",
      "\t\tOut of 262144 , 54000 are done in 20.254443883895874\n",
      "\t\tOut of 262144 , 55000 are done in 23.42482280731201\n",
      "\t\tOut of 262144 , 56000 are done in 19.896620988845825\n",
      "\t\tOut of 262144 , 57000 are done in 20.40304160118103\n",
      "\t\tOut of 262144 , 58000 are done in 19.302445888519287\n",
      "\t\tOut of 262144 , 59000 are done in 23.18332600593567\n",
      "\t\tOut of 262144 , 60000 are done in 22.164657831192017\n",
      "\t\tOut of 262144 , 61000 are done in 19.391642093658447\n",
      "\t\tOut of 262144 , 62000 are done in 18.923363208770752\n",
      "\t\tOut of 262144 , 63000 are done in 21.955663204193115\n",
      "\t\tOut of 262144 , 64000 are done in 15.590248346328735\n",
      "\t\tOut of 262144 , 65000 are done in 20.914159536361694\n",
      "\t\tOut of 262144 , 66000 are done in 22.90961241722107\n",
      "\t\tOut of 262144 , 67000 are done in 20.690558910369873\n",
      "\t\tOut of 262144 , 68000 are done in 18.461264848709106\n",
      "\t\tOut of 262144 , 69000 are done in 16.83990979194641\n",
      "\t\tOut of 262144 , 70000 are done in 10.111504793167114\n",
      "\t\tOut of 262144 , 71000 are done in 10.083491325378418\n",
      "\t\tOut of 262144 , 72000 are done in 10.082101583480835\n",
      "\t\tOut of 262144 , 73000 are done in 10.118965864181519\n",
      "\t\tOut of 262144 , 74000 are done in 10.104180097579956\n",
      "\t\tOut of 262144 , 75000 are done in 10.121810913085938\n",
      "\t\tOut of 262144 , 76000 are done in 10.107550144195557\n",
      "\t\tOut of 262144 , 77000 are done in 10.12853717803955\n",
      "\t\tOut of 262144 , 78000 are done in 10.132898569107056\n",
      "\t\tOut of 262144 , 79000 are done in 10.135896682739258\n",
      "\t\tOut of 262144 , 80000 are done in 10.108948945999146\n",
      "\t\tOut of 262144 , 81000 are done in 10.162113428115845\n",
      "\t\tOut of 262144 , 82000 are done in 10.113961219787598\n",
      "\t\tOut of 262144 , 83000 are done in 10.130296468734741\n",
      "\t\tOut of 262144 , 84000 are done in 10.106101751327515\n",
      "\t\tOut of 262144 , 85000 are done in 10.150305986404419\n",
      "\t\tOut of 262144 , 86000 are done in 10.1221764087677\n",
      "\t\tOut of 262144 , 205000 are done in 18.466233015060425\n",
      "\t\tOut of 262144 , 206000 are done in 18.558012008666992\n",
      "\t\tOut of 262144 , 207000 are done in 19.57003688812256\n",
      "\t\tOut of 262144 , 208000 are done in 18.508302211761475\n",
      "\t\tOut of 262144 , 209000 are done in 18.621241331100464\n",
      "\t\tOut of 262144 , 210000 are done in 18.565410375595093\n",
      "\t\tOut of 262144 , 211000 are done in 18.55511975288391\n",
      "\t\tOut of 262144 , 212000 are done in 18.503345251083374\n",
      "\t\tOut of 262144 , 213000 are done in 18.63335394859314\n",
      "\t\tOut of 262144 , 214000 are done in 18.484922647476196\n",
      "\t\tOut of 262144 , 215000 are done in 18.497279167175293\n",
      "\t\tOut of 262144 , 216000 are done in 18.39795708656311\n",
      "\t\tOut of 262144 , 217000 are done in 18.57766056060791\n",
      "\t\tOut of 262144 , 218000 are done in 18.56173324584961\n",
      "\t\tOut of 262144 , 219000 are done in 18.570303440093994\n",
      "\t\tOut of 262144 , 220000 are done in 18.53005027770996\n",
      "\t\tOut of 262144 , 221000 are done in 18.558936834335327\n",
      "\t\tOut of 262144 , 222000 are done in 18.58596444129944\n",
      "\t\tOut of 262144 , 223000 are done in 18.54768681526184\n",
      "\t\tOut of 262144 , 224000 are done in 18.676508903503418\n",
      "\t\tOut of 262144 , 225000 are done in 18.64726161956787\n",
      "\t\tOut of 262144 , 226000 are done in 18.454561710357666\n",
      "\t\tOut of 262144 , 227000 are done in 18.688666820526123\n",
      "\t\tOut of 262144 , 228000 are done in 18.609824895858765\n",
      "\t\tOut of 262144 , 229000 are done in 18.6915385723114\n",
      "\t\tOut of 262144 , 230000 are done in 18.583799600601196\n",
      "\t\tOut of 262144 , 231000 are done in 18.699745655059814\n",
      "\t\tOut of 262144 , 232000 are done in 18.529836177825928\n",
      "\t\tOut of 262144 , 233000 are done in 18.515930891036987\n",
      "\t\tOut of 262144 , 234000 are done in 18.66757297515869\n",
      "\t\tOut of 262144 , 235000 are done in 18.51530933380127\n",
      "\t\tOut of 262144 , 236000 are done in 18.537254095077515\n",
      "\t\tOut of 262144 , 237000 are done in 18.553959846496582\n",
      "\t\tOut of 262144 , 238000 are done in 18.594802379608154\n",
      "\t\tOut of 262144 , 239000 are done in 18.544607877731323\n",
      "\t\tOut of 262144 , 240000 are done in 18.540743589401245\n",
      "\t\tOut of 262144 , 241000 are done in 18.690377473831177\n",
      "\t\tOut of 262144 , 242000 are done in 18.594364881515503\n",
      "\t\tOut of 262144 , 243000 are done in 18.604743242263794\n",
      "\t\tOut of 262144 , 244000 are done in 18.639386892318726\n",
      "\t\tOut of 262144 , 245000 are done in 18.458006858825684\n",
      "\t\tOut of 262144 , 246000 are done in 18.42414116859436\n",
      "\t\tOut of 262144 , 247000 are done in 18.42192554473877\n",
      "\t\tOut of 262144 , 248000 are done in 18.553027391433716\n",
      "\t\tOut of 262144 , 249000 are done in 18.514472246170044\n",
      "\t\tOut of 262144 , 250000 are done in 18.49123191833496\n",
      "\t\tOut of 262144 , 251000 are done in 18.56206178665161\n",
      "\t\tOut of 262144 , 252000 are done in 18.527234315872192\n",
      "\t\tOut of 262144 , 253000 are done in 18.564496517181396\n",
      "\t\tOut of 262144 , 254000 are done in 18.61540699005127\n",
      "\t\tOut of 262144 , 255000 are done in 18.52598285675049\n",
      "\t\tOut of 262144 , 256000 are done in 18.47191882133484\n",
      "\t\tOut of 262144 , 257000 are done in 18.541122674942017\n",
      "\t\tOut of 262144 , 258000 are done in 18.555189609527588\n",
      "\t\tOut of 262144 , 259000 are done in 18.510118007659912\n",
      "\t\tOut of 262144 , 260000 are done in 18.535407304763794\n",
      "\t\tOut of 262144 , 261000 are done in 18.65812397003174\n",
      "\t\tOut of 262144 , 262000 are done in 18.540337562561035\n",
      "\tDictionary SAVED for.. 472\n"
     ]
    }
   ],
   "source": [
    "\n",
    "top_patients_dict = top_voxels_predict(top_patients_dict,LUNA_model_v2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
